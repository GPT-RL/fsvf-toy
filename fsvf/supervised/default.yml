attention_dropout_rate: 0.1
batch_size: 64
dropout_rate: 0.1
emb_dim: 768
gamma: 0.9
learning_rate: 0.0001
max_dataset_step: 10_000
mlp_dim: 3072
num_actions: 5
num_heads: 8
num_generated_examples: 1000
num_layers: 12
num_train_steps: 75_000
qkv_dim: 512
seed: 0
save_frequency: 1000
steps_per_prompt: 100
test_frequency: 100
test_size: 5
