game: "Pong"
# Total number of frames seen during training.
total_frames: 40000000
# The learning rate for the Adam optimizer.
learning_rate: 2.5e-4
# Batch size used in training.
batch_size: 256
# Number of agents playing in parallel.
num_agents: 8
# Number of steps each agent performs in one policy unroll.
actor_steps: 128
# Number of training epochs per each unroll of the policy.
num_epochs: 3
# RL discount parameter.
gamma: 0.99
# Generalized Advantage Estimation parameter.
lambda_: 0.95
# The PPO clipping parameter used to clamp ratios in loss function.
clip_param: 0.1
# Weight of value function loss in the total loss.
vf_coeff: 0.5
# Weight of entropy bonus in the total loss.
entropy_coeff: 0.01
# Linearly decay learning rate and clipping parameter to zero during
# the training.
decaying_lr_and_clip_param: True
